{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbd915d2",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783197d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import json\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import torch\n",
    "T = torch.Tensor\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95794491",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('/kaggle/input/abstraction-and-reasoning-challenge/')\n",
    "training_path = data_path / 'training'\n",
    "training_tasks = sorted(os.listdir(training_path))\n",
    "\n",
    "for i in [1, 19, 8, 15, 9]:\n",
    "\n",
    "    task_file = str(training_path / training_tasks[i])\n",
    "\n",
    "    with open(task_file, 'r') as f:\n",
    "    task = json.load(f)\n",
    "\n",
    "    def plot_task(task):\n",
    "        \"\"\"\n",
    "        Plots the first train and test pairs of a specified task,\n",
    "        using same color scheme as the ARC app\n",
    "        \"\"\"\n",
    "        cmap = colors.ListedColormap(\n",
    "        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
    "        '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
    "        norm = colors.Normalize(vmin=0, vmax=9)\n",
    "        fig, ax = plt.subplots(1, 4, figsize=(15,15))\n",
    "        ax[0].imshow(task['train'][0]['input'], cmap=cmap, norm=norm)\n",
    "        width = np.shape(task['train'][0]['input'])[1]\n",
    "        height = np.shape(task['train'][0]['input'])[0]\n",
    "        ax[0].set_xticks(np.arange(0,width))\n",
    "        ax[0].set_yticks(np.arange(0,height))\n",
    "        ax[0].set_xticklabels([])\n",
    "        ax[0].set_yticklabels([])\n",
    "        ax[0].tick_params(length=0)\n",
    "        ax[0].grid(True)\n",
    "        ax[0].set_title('Train Input')\n",
    "        ax[1].imshow(task['train'][0]['output'], cmap=cmap, norm=norm)\n",
    "        width = np.shape(task['train'][0]['output'])[1]\n",
    "        height = np.shape(task['train'][0]['output'])[0]\n",
    "        ax[1].set_xticks(np.arange(0,width))\n",
    "        ax[1].set_yticks(np.arange(0,height))\n",
    "        ax[1].set_xticklabels([])\n",
    "        ax[1].set_yticklabels([])\n",
    "        ax[1].tick_params(length=0)\n",
    "        ax[1].grid(True)\n",
    "        ax[1].set_title('Train Output')\n",
    "        ax[2].imshow(task['test'][0]['input'], cmap=cmap, norm=norm)\n",
    "        width = np.shape(task['test'][0]['input'])[1]\n",
    "        height = np.shape(task['test'][0]['input'])[0]\n",
    "        ax[2].set_xticks(np.arange(0,width))\n",
    "        ax[2].set_yticks(np.arange(0,height))\n",
    "        ax[2].set_xticklabels([])\n",
    "        ax[2].set_yticklabels([])\n",
    "        ax[2].tick_params(length=0)\n",
    "        ax[2].grid(True)\n",
    "        ax[2].set_title('Test Input')\n",
    "        ax[3].imshow(task['test'][0]['output'], cmap=cmap, norm=norm)\n",
    "        width = np.shape(task['test'][0]['output'])[1]\n",
    "        height = np.shape(task['test'][0]['output'])[0]\n",
    "        ax[3].set_xticks(np.arange(0,width))\n",
    "        ax[3].set_yticks(np.arange(0,height))\n",
    "        ax[3].set_xticklabels([])\n",
    "        ax[3].set_yticklabels([])\n",
    "        ax[3].tick_params(length=0)\n",
    "        ax[3].grid(True)\n",
    "        ax[3].set_title('Test Output')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    plot_task(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce901d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(df, x=\"values\", title=\"Numbers present in matrices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2558a04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = [np.mean(X) for X in matrices]\n",
    "fig = ff.create_distplot([means], group_labels=[\"Means\"], colors=[\"green\"])\n",
    "fig.update_layout(title_text=\"Distribution of matrix mean values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f8e294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List comprehension for evaluating matix heights\n",
    "heights = [np.shape(matrix)[0] for matrix in matrices]\n",
    "# List comprehension for evaluating matix width\n",
    "widths = [np.shape(matrix)[1] for matrix in matrices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49b5d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ff.create_distplot([heights], group_labels=[\"Height\"], colors=[\"magenta\"])\n",
    "fig.update_layout(title_text=\"Distribution of matrix heights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd60e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ff.create_distplot([widths], group_labels=[\"Width\"], colors=[\"red\"])\n",
    "fig.update_layout(title_text=\"Distribution of matrix widths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d834e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.jointplot(widths, heights, kind=\"kde\", color=\"blueviolet\")\n",
    "plot.set_axis_labels(\"Width\", \"Height\", fontsize=14)\n",
    "plt.show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ee4d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.jointplot(widths, heights, kind=\"reg\", color=\"blueviolet\")\n",
    "plot.set_axis_labels(\"Width\", \"Height\", fontsize=14)\n",
    "plt.show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51e0df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_values(a, d):\n",
    "    return np.array([d.get(i, -1) for i in range(a.min(), a.max() + 1)])[a - a.min()]\n",
    "\n",
    "def repeat_matrix(a):\n",
    "    return np.concatenate([a]*((SIZE // len(a)) + 1))[:SIZE]\n",
    "\n",
    "def get_new_matrix(X):\n",
    "    if len(set([np.array(x).shape for x in X])) > 1:\n",
    "        X = np.array([X[0]])\n",
    "    return X\n",
    "\n",
    "def get_outp(outp, dictionary=None, replace=True):\n",
    "    if replace:\n",
    "        outp = replace_values(outp, dictionary)\n",
    "\n",
    "    outp_matrix_dims = outp.shape\n",
    "    outp_probs_len = outp.shape[0]*outp.shape[1]*10\n",
    "    outp = to_categorical(outp.flatten(), num_classes=10).flatten()\n",
    "\n",
    "    return outp, outp_probs_len, outp_matrix_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd7c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARCDataset(Dataset):\n",
    "    def __init__(self, X, y, stage=\"train\"):\n",
    "        self.X = get_new_matrix(X)\n",
    "        self.X = repeat_matrix(self.X)\n",
    "\n",
    "        self.stage = stage\n",
    "        if self.stage == \"train\":\n",
    "            self.y = get_new_matrix(y)\n",
    "            self.y = repeat_matrix(self.y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return SIZE\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inp = self.X[idx]\n",
    "        if self.stage == \"train\":\n",
    "            outp = self.y[idx]\n",
    "\n",
    "        if idx != 0:\n",
    "            rep = np.arange(10)\n",
    "            orig = np.arange(10)\n",
    "            np.random.shuffle(rep)\n",
    "            dictionary = dict(zip(orig, rep))\n",
    "            inp = replace_values(inp, dictionary)\n",
    "            if self.stage == \"train\":\n",
    "                outp, outp_probs_len, outp_matrix_dims = get_outp(outp, dictionary)\n",
    "\n",
    "        if idx == 0:\n",
    "            if self.stage == \"train\":\n",
    "                outp, outp_probs_len, outp_matrix_dims = get_outp(outp, None, False)\n",
    "\n",
    "        return inp, outp, outp_probs_len, outp_matrix_dims, self.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86009d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicCNNModel(nn.Module):\n",
    "    def __init__(self, inp_dim=(10, 10), outp_dim=(10, 10)):\n",
    "        super(BasicCNNModel, self).__init__()\n",
    "\n",
    "        CONV_IN = 3\n",
    "        KERNEL_SIZE = 3\n",
    "        DENSE_IN = CONV_OUT_2\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.dense_1 = nn.Linear(DENSE_IN, outp_dim[0]*outp_dim[1]*10)\n",
    "\n",
    "        if inp_dim[0] < 5 or inp_dim[1] < 5:\n",
    "        KERNEL_SIZE = 1\n",
    "\n",
    "        self.conv2d_1 = nn.Conv2d(CONV_IN, CONV_OUT_1, kernel_size=KERNEL_SIZE)\n",
    "        self.conv2d_2 = nn.Conv2d(CONV_OUT_1, CONV_OUT_2, kernel_size=KERNEL_SIZE)\n",
    "\n",
    "        def forward(self, x, outp_dim):\n",
    "        x = torch.cat([x.unsqueeze(0)]*3)\n",
    "        x = x.permute((1, 0, 2, 3)).float()\n",
    "        self.conv2d_1.in_features = x.shape[1]\n",
    "        conv_1_out = self.relu(self.conv2d_1(x))\n",
    "        self.conv2d_2.in_features = conv_1_out.shape[1]\n",
    "        conv_2_out = self.relu(self.conv2d_2(conv_1_out))\n",
    "\n",
    "        self.dense_1.out_features = outp_dim\n",
    "        feature_vector, _ = torch.max(conv_2_out, 2)\n",
    "        feature_vector, _ = torch.max(feature_vector, 2)\n",
    "        logit_outputs = self.dense_1(feature_vector)\n",
    "\n",
    "        out = []\n",
    "        for idx in range(logit_outputs.shape[1]//10):\n",
    "        out.append(self.softmax(logit_outputs[:, idx*10: (idx+1)*10]))\n",
    "        return torch.cat(out, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684a4309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dim(inp_dim, outp_dim, test_dim):\n",
    "    return (test_dim[0]*outp_dim[0]/inp_dim[0],\n",
    "        test_dim[1]*outp_dim[1]/inp_dim[1])\n",
    "\n",
    "def resize(x, test_dim, inp_dim):\n",
    "    if inp_dim == test_dim:\n",
    "        return x\n",
    "    else:\n",
    "        return cv2.resize(flt(x), inp_dim, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def flt(x): return np.float32(x)\n",
    "def npy(x): return x.cpu().detach().numpy()\n",
    "def itg(x): return np.int32(np.round(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9952fc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "start = time.time()\n",
    "test_predictions = []\n",
    "\n",
    "for X_train, y_train in zip(Xs_train, ys_train):\n",
    "    print(\"TASK \" + str(idx + 1))\n",
    "\n",
    "    train_set = ARCDataset(X_train, y_train, stage=\"train\")\n",
    "    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    inp_dim = np.array(X_train[0]).shape\n",
    "    outp_dim = np.array(y_train[0]).shape\n",
    "    network = BasicCNNModel(inp_dim, outp_dim).cuda()\n",
    "    optimizer = Adam(network.parameters(), lr=0.01)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        for train_batch in train_loader:\n",
    "            train_X, train_y, out_d, d, out = train_batch\n",
    "            train_preds = network.forward(train_X.cuda(), out_d.cuda())\n",
    "            train_loss = nn.MSELoss()(train_preds, train_y.cuda())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    end = time.time()        \n",
    "    print(\"Train loss: \" + str(np.round(train_loss.item(), 3)) + \"   \" +\\\n",
    "    \"Total time: \" + str(np.round(end - start, 1)) + \" s\" + \"\\n\")\n",
    "\n",
    "    X_test = np.array([resize(flt(X), np.shape(X), inp_dim) for X in Xs_test[idx-1]])\n",
    "    for X in X_test:\n",
    "        test_dim = np.array(T(X)).shape\n",
    "        test_preds = npy(network.forward(T(X).unsqueeze(0).cuda(), out_d.cuda()))\n",
    "        test_preds = np.argmax(test_preds.reshape((10, *outp_dim)), axis=0)\n",
    "        test_predictions.append(itg(resize(test_preds, np.shape(test_preds),\n",
    "        tuple(itg(transform_dim(inp_dim,\n",
    "        outp_dim,\n",
    "        test_dim))))))\n",
    "        idx += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
